name: LLM-HCG
config:

  # The model tag to use for the LLM.
  model: gpt-4o-mini

  # Inference hyperparameters.
  n_samples_inference: 5
  method_inference_sampling: uniform
  num_attempts_inference: 5

  # Update hyperparameters.
  n_samples_update: 10
  method_update_sampling: uniform
  n_max_update_new_primitives: 5
  n_max_update_refactorings: 3
  num_attemps_update_code_extraction: 5
  num_attempts_update_pc_code_execution: 5
  num_attempts_update_sc_code_execution: 5

  

  # The config for the controller library.
  config_controllers:
    which_initial_controllers: specific  # none, specific (those in initial_controllers), all (all available in agent.llm_hcg.initial_controllers)
    initial_controllers:
      - move_forward.py
      - turn_to_direction.py

  config_functions:
    do_use: False

  config_knowledges:
    do_use: False

  config_hypotheses:
    do_use: False
    
  config_logs:
    # The directory to save logs to.
    log_dir: logs
    # Whether to log the run on log_dir/<run name>
    do_log_on_new: False
    # Whether to log the run on log_dir/_last
    do_log_on_last: True

  config_debug:
    # Whether to breakpoint on inference events
    breakpoint_inference: False
    breakpoint_inference_on_failure_code_extraction: False
    breakpoint_inference_on_failure_code_execution: False
    # Whether to breakpoint on update events
    breakpoint_update: False
    breakpoint_update_on_failure_code_extraction: True
    breakpoint_update_on_failure_pc_code_execution: True
    breakpoint_update_on_failure_sc_code_execution: True