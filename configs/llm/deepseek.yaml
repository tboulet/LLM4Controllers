name: FromAPI
api_key_name: DEEPSEEK_API_KEY
model: deepseek-chat
config:
  client:
    _target_: openai.OpenAI
    api_key: ${env_variable:'${llm.api_key_name}'}
    base_url: https://api.deepseek.com/v1
  model: ${llm.model}
  config_inference:
    max_tokens: 4096
    temperature: 0.5
    top_p: 0.9
  max_retries: 20
