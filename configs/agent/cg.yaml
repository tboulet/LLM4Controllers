name: CG
config:

  # The model tag to use for the LLM (in case the LLM class requires a model tag).
  model: gpt-4o-mini

  # Which prompt to use
  list_prompt_keys:
    - system
    - env
    - controller_structure
    - example_answer
    - task
    - task_description
    - instructions

  # The number of attemps to get a correct answer from the LLM before crashing
  num_attempts_inference: 5

  # The number of inference calls to make
  n_inferences: 1

  # The number of episodes on which a controller will be evaluated on a task
  n_episodes_eval: 5

  # The parameter for the pass@k metric
  k_pass: ${eval:'min(${agent.config.n_inferences}, 5)'}

  # The LLM config to use
  llm: ${llm}

  config_debug:
    # Whether to breakpoint on inference events
    breakpoint_inference: False
    breakpoint_inference_on_failure_code_extraction: False
    breakpoint_inference_on_failure_code_execution: False
    # Whether to breakpoint on update events
    breakpoint_update: False
    breakpoint_update_on_failure_code_extraction: True
    breakpoint_update_on_failure_pc_code_saving: True
    breakpoint_update_on_failure_sc_code_execution: True
    
  config_logs: ${config_logs}